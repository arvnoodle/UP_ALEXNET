{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Members:**\n",
        "*   Gaw, Janice Ko\n",
        "*   Sepe, Jean Marlo\n",
        "*   Ramos, Paula Angelica\n",
        "*   Flores, Arvin Christian\n",
        "\n"
      ],
      "metadata": {
        "id": "ms0XqpLhsNRy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubPUcaGnl9iH"
      },
      "source": [
        "### A. LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_IQnWam5Oep",
        "outputId": "48637188-bfa9-4506-c983-831b874f9fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (5.29.5)\n",
            "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.4\n"
          ]
        }
      ],
      "source": [
        "pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgslfHsZKcZG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEGHQJPkb2F8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f03785-ef22-4f9a-f441-a1e0ba2c8378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: False\n",
            "GPU name: CPU\n"
          ]
        }
      ],
      "source": [
        "# ---- rp16/added!\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VanizTmZo6JT"
      },
      "source": [
        "### B. MODEL PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU4rrduno2mV"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implementation of AlexNet, from paper\n",
        "\"ImageNet Classification with Deep Convolutional Neural Networks\" by Alex Krizhevsky et al.\n",
        "\n",
        "See: https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
        "\n",
        "\n",
        "Data\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes,\n",
        "with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "See: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# define pytorch device - useful for device-agnostic execution\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# define model parameters\n",
        "NUM_EPOCHS = 90  # original paper - 90\n",
        "BATCH_SIZE = 128\n",
        "MOMENTUM = 0.9\n",
        "LR_DECAY = 0.0005\n",
        "LR_INIT = 0.01\n",
        "IMAGE_DIM = 227  # pixels for the ImageNet dataset. CIFAR-10 dataset images will be resized during data loading\n",
        "NUM_CLASSES = 10  # 10 classes for CIFAR-10 dataset\n",
        "DEVICE_IDS = [0, 1, 2, 3]  # GPUs to use\n",
        "\n",
        "# modify this to point to your data directory\n",
        "INPUT_ROOT_DIR = 'alexnet_data_in'\n",
        "TRAIN_IMG_DIR = 'alexnet_data_in/cifar'\n",
        "OUTPUT_DIR = 'alexnet_data_out'\n",
        "LOG_DIR = OUTPUT_DIR + '/tblogs'  # tensorboard logs\n",
        "CHECKPOINT_DIR = OUTPUT_DIR + '/models'  # model checkpoints\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# make checkpoint path directory\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9pAukgSErMH"
      },
      "source": [
        "### C. MODEL ARCHITECTURE\n",
        "\n",
        "\n",
        "1.   Feature Extractor (Convolution + Pooling Layers)\n",
        "2.   Classifier (Fully Connected Layers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ETp5vtpMt4w"
      },
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Neural network model consisting of layers proposed by AlexNet paper.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        \"\"\"\n",
        "        Define and allocate layers for this neural net.\n",
        "\n",
        "        Args:\n",
        "            num_classes (int): number of classes to predict with this model\n",
        "        \"\"\"\n",
        "\n",
        "        # JANICE ----------------------------------------------------------------\n",
        "\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        # To get the output size of a convolutional layer:\n",
        "        # output = [ (input - kernel + padding at the start + padding at the end)/ stride ] + 1\n",
        "        # reference: https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks\n",
        "\n",
        "        # Architercture for the ImageNet dataset.\n",
        "        # Input size adjusted to (b x 3 x 227 x 227)\n",
        "        # The image in the original paper states that width and height are 224 pixels,\n",
        "        # but the dimensions after first convolution layer do not lead to 55 x 55.\n",
        "\n",
        "        # CIFAR-10 images will be resized to retain the architecture as is.\n",
        "\n",
        "        # BatchNorm2d reference:\n",
        "        # https://medium.com/@benjybo7/6-pytorch-normalization-layers-used-in-all-deep-learning-models-b565853b1fbc\n",
        "        # https://www.ultralytics.com/glossary/batch-normalization\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Convolutional layer 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),     # (b x 96 x 55 x 55)\n",
        "            nn.ReLU(),\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # Can be replaced with nn.BatchNorm2d(96) if any error encountered\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 96 x 27 x 27)\n",
        "            # Convolutional layer 2\n",
        "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2),   # (b x 256 x 27 x 27)\n",
        "            nn.ReLU(),\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # Can be replaced with nn.BatchNorm2d(256) if any error encountered\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 13 x 13)\n",
        "            # Convolutional layer 3\n",
        "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1),  # (b x 384 x 13 x 13)\n",
        "            nn.ReLU(),\n",
        "            # Convolutional layer 4\n",
        "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1),  # (b x 384 x 13 x 13)\n",
        "            nn.ReLU(),\n",
        "            # Convolutional layer 5\n",
        "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),  # (b x 256 x 13 x 13)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),  # (b x 256 x 6 x 6)\n",
        "        )\n",
        "\n",
        "        # PAULA ----------------------------------------------------------------\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(in_features=(256 * 6 * 6), out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=num_classes),\n",
        "        )\n",
        "        self.init_bias()  # initialize bias\n",
        "\n",
        "    def init_bias(self):\n",
        "        for layer in self.features:\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
        "                nn.init.constant_(layer.bias, 0)\n",
        "        # original paper = 1 for Conv2d layers 2nd, 4th, and 5th conv layers\n",
        "        nn.init.constant_(self.features[4].bias, 1)\n",
        "        nn.init.constant_(self.features[10].bias, 1)\n",
        "        nn.init.constant_(self.features[12].bias, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Pass the input through the net.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): input tensor\n",
        "\n",
        "        Returns:\n",
        "            output (Tensor): output tensor\n",
        "        \"\"\"\n",
        "        x = self.features(x)\n",
        "        x = x.view(-1, 256 * 6 * 6)  # reduce the dimensions for linear layer input.\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2eRTm3Gk1lH"
      },
      "source": [
        "### D. DATA PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwlLeyvXEY27",
        "outputId": "65bef993-5794-4366-8682-cc3a27d9daec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 41.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets created\n",
            "Dataloaders created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# JM----------------------------------------------------------------------\n",
        "# TRANSFORMATIONS, DATASETS AND DATALOADER\n",
        "\n",
        "# Define transformation and augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),  # to resize CIFAR-10 images and retain the AlexNet architecture as is\n",
        "    transforms.RandomHorizontalFlip(), #data augmentation for test data\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),  # to resize CIFAR-10 images and retain the AlexNet architecture as is\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
        "])\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "train_dataset = CIFAR10(root='./data', train=True, transform=train_transform, download=True)\n",
        "test_dataset = CIFAR10(root='./data', train=False, transform=test_transform, download=True)\n",
        "print('Datasets created')\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          shuffle=True,\n",
        "                          pin_memory=True,\n",
        "                          num_workers=8,\n",
        "                          drop_last=True,\n",
        "                          batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                          shuffle=True,\n",
        "                          pin_memory=True,\n",
        "                          num_workers=8,\n",
        "                          drop_last=True,\n",
        "                          batch_size=BATCH_SIZE)\n",
        "print('Dataloaders created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah1CX3LfFruC"
      },
      "source": [
        "### E. TRAINING PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWe1EnZbEd_N",
        "outputId": "97a87e7d-4964-454f-93a3-01bdc047832c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used seed : 8573561166426702098\n",
            "TensorboardX summary writer created\n",
            "DataParallel(\n",
            "  (module): AlexNet(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
            "      (1): ReLU()\n",
            "      (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
            "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (5): ReLU()\n",
            "      (6): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
            "      (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (9): ReLU()\n",
            "      (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): ReLU()\n",
            "      (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): ReLU()\n",
            "      (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (classifier): Sequential(\n",
            "      (0): Dropout(p=0.5, inplace=False)\n",
            "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "      (2): ReLU()\n",
            "      (3): Dropout(p=0.5, inplace=False)\n",
            "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (5): ReLU()\n",
            "      (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "AlexNet created\n",
            "LR Scheduler created\n"
          ]
        }
      ],
      "source": [
        "# MODEL\n",
        "\n",
        "# print the seed value\n",
        "seed = torch.initial_seed()\n",
        "print('Used seed : {}'.format(seed))\n",
        "\n",
        "tbwriter = SummaryWriter(log_dir=LOG_DIR)\n",
        "print('TensorboardX summary writer created')\n",
        "\n",
        "# create model\n",
        "alexnet = AlexNet(num_classes=NUM_CLASSES).to(device)\n",
        "\n",
        "# train on multiple GPUs. different mechanism compared to the manual model-splitting in the paper\n",
        "alexnet = torch.nn.parallel.DataParallel(alexnet, device_ids=DEVICE_IDS)\n",
        "print(alexnet)\n",
        "print('AlexNet created')\n",
        "\n",
        "# LOSS FUNCTION AND OPTIMIZER\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.SGD(alexnet.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# multiply LR by 1 / 10 after every 30 epochs\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "print('LR Scheduler created')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST IMAGE"
      ],
      "metadata": {
        "id": "P_OaqwYnramS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# create tiny dataset with one 2x2 image per split\n",
        "for split in [\"train\", \"test\"]:\n",
        "    os.makedirs(f\"tiny_data/{split}/class0\", exist_ok=True)\n",
        "    img = Image.fromarray(np.array([[[255,0,0],[0,255,0]],\n",
        "                                    [[0,0,255],[255,255,0]]], dtype=np.uint8))\n",
        "    img.save(f\"tiny_data/{split}/class0/dummy.png\")\n",
        "\n",
        "tiny_transform = transforms.Compose([\n",
        "    transforms.Resize((227,227)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = ImageFolder(root=\"tiny_data/train\", transform=tiny_transform)\n",
        "test_dataset  = ImageFolder(root=\"tiny_data/test\",  transform=tiny_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=1, num_workers=0)\n",
        "test_loader  = DataLoader(test_dataset,  shuffle=False, batch_size=1, num_workers=0)\n"
      ],
      "metadata": {
        "id": "dRCFWKcNq_Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQXHKbj322eF",
        "outputId": "60afb57e-994b-404e-a4ee-3324402a3dc4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ],
      "source": [
        "#TRAINING LOOP\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    lr_scheduler.step()\n",
        "    alexnet.train()  # set the model to training mode\n",
        "    running_loss = 0.0  # track the loss for each epoch\n",
        "    total_steps = 1\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "        # move tensors to the configured device\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # forward pass, calculate the loss\n",
        "        outputs = alexnet(images) #forward pass\n",
        "        loss = criterion(outputs, labels)  # compute loss\n",
        "\n",
        "        # backward, optimize, and update the parameters\n",
        "        optimizer.zero_grad()  # zero the gradient buffers\n",
        "        loss.backward()  # backward pass\n",
        "        optimizer.step()  # update model weights\n",
        "\n",
        "        running_loss += loss.item()  # Accumulate loss\n",
        "        total_steps += 1\n",
        "\n",
        "    alexnet.eval() # Set the model to evaluation mode\n",
        "    correct, total = 0, 0\n",
        "    val_loss = 0.0 # track the validation loss for each epoch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "\n",
        "            # move tensors to the configured device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # forward pass, calculate the loss\n",
        "            outputs = alexnet(inputs) # forward pass\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1) # get the class with highest probability\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    avg_val_loss = val_loss / len(test_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    total_steps += 1\n",
        "\n",
        "    # print train loss, test loss and accuracy for the epoch\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss}, Test Loss: {avg_val_loss}, Accuracy: {accuracy}\")\n",
        "\n",
        "    # save checkpoints\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, 'alexnet_states_e{}.pkl'.format(epoch+1))\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'total_steps': total_steps,\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'model': alexnet.state_dict(),\n",
        "        'seed': seed,\n",
        "    }\n",
        "    torch.save(state, checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcXDfHMiFvQY"
      },
      "source": [
        "### F. INFERENCE AND EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8L8TQ1uElQS"
      },
      "outputs": [],
      "source": [
        "# ARVIN --------------------------------------------------------------------------------\n",
        "# start training!!\n",
        "    print('Starting training...')\n",
        "    total_steps = 1\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        lr_scheduler.step()\n",
        "        for imgs, classes in train_loader:\n",
        "\n",
        "            # move tensors to the configured device\n",
        "            imgs, classes = imgs.to(device), classes.to(device)\n",
        "\n",
        "            # forward pass, calculate the loss\n",
        "            output = alexnet(imgs)\n",
        "            loss = criterion(output, classes)\n",
        "\n",
        "            # backward, optimize, and update the parameters\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # log the information and add to tensorboard\n",
        "            if total_steps % 10 == 0:\n",
        "                with torch.no_grad():\n",
        "                    _, preds = torch.max(output, 1)\n",
        "                    accuracy = torch.sum(preds == classes)\n",
        "\n",
        "                    print('Epoch: {} \\tStep: {} \\tLoss: {:.4f} \\tAcc: {}'\n",
        "                        .format(epoch + 1, total_steps, loss.item(), accuracy.item()))\n",
        "                    tbwriter.add_scalar('loss', loss.item(), total_steps)\n",
        "                    tbwriter.add_scalar('accuracy', accuracy.item(), total_steps)\n",
        "\n",
        "            # print out gradient values and parameter average values\n",
        "            if total_steps % 100 == 0:\n",
        "                with torch.no_grad():\n",
        "                    # print and save the grad of the parameters\n",
        "                    # also print and save parameter values\n",
        "                    print('*' * 10)\n",
        "                    for name, parameter in alexnet.named_parameters():\n",
        "                        if parameter.grad is not None:\n",
        "                            avg_grad = torch.mean(parameter.grad)\n",
        "                            print('\\t{} - grad_avg: {}'.format(name, avg_grad))\n",
        "                            tbwriter.add_scalar('grad_avg/{}'.format(name), avg_grad.item(), total_steps)\n",
        "                            tbwriter.add_histogram('grad/{}'.format(name),\n",
        "                                    parameter.grad.cpu().numpy(), total_steps)\n",
        "                        if parameter.data is not None:\n",
        "                            avg_weight = torch.mean(parameter.data)\n",
        "                            print('\\t{} - param_avg: {}'.format(name, avg_weight))\n",
        "                            tbwriter.add_histogram('weight/{}'.format(name),\n",
        "                                    parameter.data.cpu().numpy(), total_steps)\n",
        "                            tbwriter.add_scalar('weight_avg/{}'.format(name), avg_weight.item(), total_steps)\n",
        "\n",
        "            total_steps += 1\n",
        "\n",
        "        # save checkpoints\n",
        "        checkpoint_path = os.path.join(CHECKPOINT_DIR, 'alexnet_states_e{}.pkl'.format(epoch + 1))\n",
        "        state = {\n",
        "            'epoch': epoch,\n",
        "            'total_steps': total_steps,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'model': alexnet.state_dict(),\n",
        "            'seed': seed,\n",
        "        }\n",
        "        torch.save(state, checkpoint_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}